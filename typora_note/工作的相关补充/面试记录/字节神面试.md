## 问题1：hashmap哪个是保证读写顺序的？

答案：LinkedHashMap

其实当时没有太理解这个题目，所以直接回答的是treeMap。其实treeMap是保证了：Map可以**保持key的大小顺序**。

​	LinkedHashMap是**Hash表**和**链表**的实现，并且依靠着双向链表保证了迭代顺序是插入的顺序。

​	LinkedHashMap的有序可以按两种顺序排列，一种是按照插入的顺序，一种是按照读取的顺序（这个题目的示例就是告诉我们要按照读取的顺序进行排序），而其内部是靠 建立一个双向链表 来维护这个顺序的，在每次插入、删除后，都会调用一个函数来进行 双向链表的维护 ，准确的来说，是有三个函数来做这件事，这三个函数都统称为 回调函数 ，这三个函数分别是：

**void afterNodeAccess(Node<K,V> p) { }**
		其作用就是在访问元素之后，将该元素放到双向链表的尾巴处(所以这个函数只有在按照读取的顺序的时候才会执行)，之所以提这个，是建议大家去看看，如何优美的实现在双向链表中将指定元素放入链尾！
**void afterNodeRemoval(Node<K,V> p) { }**
		其作用就是在删除元素之后，将元素从双向链表中删除，还是非常建议大家去看看这个函数的，很优美的方式在双向链表中删除节点！
**void afterNodeInsertion(boolean evict) { }**
		这个才是我们题目中会用到的，在插入新元素之后，需要回调函数判断是否需要移除一直不用的某些元素！

​		

看到这边，其实就很容易想到LRU缓存机制：https://leetcode-cn.com/problems/lru-cache/solution/yuan-yu-linkedhashmapyuan-ma-by-jeromememory/

LinkedHashMap，在构造函数中，如果设定了accessOrder=True，那就能保证，最新操作的Node，一直在双向链表的**最后**（注意是最后，这个和我自己写的LRU题解是链表顺序是相反的，我自己写的是最先访问的放在最前面，但是LinkedHashMap是最多访问的放在最后）。

参考资料：

https://www.cnblogs.com/LiaHon/p/11180869.html

http://www.androidos.net.cn/b/android-road/4247494824.html

https://leetcode-cn.com/problems/lru-cache/solution/yuan-yu-linkedhashmapyuan-ma-by-jeromememory/

```java
class LRUCache extends LinkedHashMap<Integer, Integer>{
    private int capacity;
    
    public LRUCache(int capacity) {
        super(capacity, 0.75F, true);
        this.capacity = capacity;
    }

    public int get(int key) {
        return super.getOrDefault(key, -1);
    }

    // 这个可不写
    public void put(int key, int value) {
        super.put(key, value);
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
        return size() > capacity; 
    }
}


作者：jeromememory
链接：https://leetcode-cn.com/problems/lru-cache/solution/yuan-yu-linkedhashmapyuan-ma-by-jeromememory/
来源：力扣（LeetCode）
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```



## 问题2：currentHashmap 哪些地方用了synchronized 哪些地方用了cas？

​	在JDK1.8中摒弃了Segment分段锁的数据结构，基于**CAS**操作保证数据的获取以及使用**synchronized关键字**对相应数据段加锁来实现线程安全，这进一步提高了并发性。

回答：

**1.数组初始化时的线程安全**

数组初始化时，首先通过自旋来保证一定可以初始化成功，然后通过 CAS 设置 SIZECTL 变量的值，来保证同一时刻只能有一个线程对数组进行初始化，CAS 成功之后，还会再次判断当前数组是否已经初始化完成，如果已经初始化完成，就不会再次初始化，通过自旋 + CAS + 双重 check 等手段保证了数组初始化时的线程安全

sizeCtl：

1、-1 代表有线程正在创建 table；

2、-N 代表有 N-1 个线程正在复制 table；

3、在 table 被初始化前，代表根据构造函数传入的值计算出的应被初始化的大小；

4、在 table 被初始化后，则被设置为 table 大小 的 75%，代表 table 的容量（数组容量）。



**2.put的时候**

​	1.通过自旋死循环保证一定可以新增成功。

​	2.当前槽点为空时，通过 CAS 新增。

​	3.当前槽点有值，锁住当前槽点。

​	4.红黑树旋转时，锁住红黑树的根节点，保证同一时刻，当前红黑树只能被一个线程旋转



**3.扩容的时候**

CAS保证只有一个线程能够操作sizeCtl

put的操作让别的线程意识到在扩容的时候，一起帮忙扩容。（put 时碰到转移节点时会等待扩容成功之后才能 put 的策略，来保证了整个扩容过程中肯定是线程安全的，因为数组的槽点一旦被设置成转移节点，在没有扩容完成之前，是无法进行操作的）



### 	1.基本数据结构Node

```
class Node<K,V> implements Map.Entry<K,V> {
 final int hash;
 final K key;
 volatile V val;
 volatile Node<K,V> next;
 ... 省略部分代码
}
```

​	其中value和next都用volatile修饰，保证并发的可见性。（get操作全程不需要加锁是因为Node的成员val是用volatile修饰的）

​	ConcurrentHashMap**中查找元素、替换元素和赋值元素**都是基于`sun.misc.Unsafe`中**原子操作**实现**多并发的无锁化**操作。

### 	2.初始化（使用了CAS）	

```
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
//如果一个线程发现sizeCtl<0，意味着另外的线程执行CAS操作成功，当前线程只需要让出cpu时间片
        if ((sc = sizeCtl) < 0) 
            Thread.yield(); // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

### 	3.put操作（CAS+synchronized）

​		假设table已经初始化完成，put操作采用CAS+synchronized实现并发插入或更新操作，具体实现如下

#### 		**1.**如果key或者value为null，则抛出空指针异常，和HashMap不同的是HashMap单线程是允许为Null；

```
if (key == null || value == null) throw new NullPointerException();
```

​		`ConcurrentHashmap`和`hashMap`不同的是，`concurrentHashMap`的`key`和`value`都不允许为null，因为`concurrenthashmap`它们是用于多线程的，并发的 ，如果`map.get(key)`得到了null，不能判断到底是映射的value是null,还是因为没有找到对应的key而为空，而用于单线程状态的`hashmap`却可以用`containKey（key）` 去判断到底是否包含了这个null。

#### 		2. hash、定位

```
static final int spread(int h) {return (h ^ (h >>> 16)) & HASH_BITS;}
```

```
int index = (n - 1) & hash
```

#### 		3.获取table中对应索引的元素（如果对应位置为null，也就是无冲突的话  CAS插入 ）。

​		通过`tableAt()`方法找到位置`tab[i]`的`Node`,当Node为null时为没有`hash`冲突的话，使用`casTabAt()`方法`CAS`操作将元素插入到`Hash`表中，`ConcurrentHashmap`使用`CAS`无锁化操作，这样在高并发`hash`冲突低的情况下，性能良好。	

```
else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
  //利用CAS操作将元素插入到Hash表中
 if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))
 break;  // no lock when adding to empty bin(插入null的节点，无需加锁)
            }
```

		Doug Lea采用Unsafe.getObjectVolatile来获取，也许有人质疑，直接table[index]不可以么，为什么要这么复杂？

​		在java内存模型中，我们已经知道每个线程都有一个工作内存，里面存储着table的副本，虽然table是volatile修饰的，但不能保证线程每次都拿到table中的最新元素，Unsafe.getObjectVolatile可以直接获取指定内存的数据，保证了每次拿到数据都是最新的。

#### 		4.如果发生了冲突，且是现在在扩容的情况

​			当f不为null时，说明发生了hash冲突，当f.hash == MOVED==-1 时，说明`ConcurrentHashmap`正在发生`resize`操作,使用`helpTransfer()`方法帮助正在进行resize操作。

```
else if ((fh = f.hash) == MOVED) //f.hash == -1 
 //hash为-1 说明是一个forwarding nodes节点，表明正在扩容
 tab = helpTransfer(tab, f);
```

#### 		5.其余情况（synchronized+DCL double check）

​	其余情况把新的Node节点按链表或红黑树的方式插入到合适的位置，这个过程采用**同步内置锁synchronized**实现并发，代码如下:

​	在节点f上进行同步，节点插入之前，再次利用tabAt(tab, i) == f判断，防止被其它线程修改。

1. 如果f.hash >= 0，说明f是链表结构的头结点，遍历链表，如果找到对应的node节点，则修改value，否则在链表尾部加入节点。
2. 如果f是TreeBin类型节点，说明f是红黑树根节点，则在树结构上遍历元素，更新或增加节点。
3. 如果链表中节点数binCount >= TREEIFY_THRESHOLD(默认是8)，则把链表转化为红黑树结构。

### 4.节点扩容（有涉及CAS）（put操作能够让我们一起扩容）

当table容量不足的时候，即table的元素数量达到容量阈值sizeCtl，需要对table进行扩容。
整个扩容分为两部分：

1. 构建一个nextTable，大小为table的两倍。
2. 把table的数据复制到nextTable中。

这两个过程在单线程下实现很简单，但是ConcurrentHashMap是支持并发插入的，扩容操作自然也会有并发的出现，这种情况下，第二步可以支持节点的并发复制，这样性能自然提升不少，但实现的复杂度也上升了一个台阶。

通过Unsafe.compareAndSwapInt修改sizeCtl值，保证只有一个线程能够初始化nextTable，扩容后的数组长度为原来的两倍，但是容量是原来的1.5。

具体看张老师的那个安卓的参考即可。



参考文章：

https://zhuanlan.zhihu.com/p/237295675

http://www.androidos.net.cn/b/android-road/2224538299.html

https://www.cnblogs.com/tiancai/p/13297793.html

https://zhuanlan.zhihu.com/p/268702928



## 问题3：String的hashcode是怎么实现的？

```
public int hashCode() {
    int h = hash;// 默认值是0
    if (h == 0 && value.length > 0) {
        char val[] = value;

        for (int i = 0; i < value.length; i++) {
            h = 31 * h + val[i];
        }
        hash = h;
    }
    return h;
}
```

String类中的hashCode计算方法还是比较简单的，就是以31为权，每一位为字符的ASCII值进行运算，用自然溢出来等效取模。

哈希计算公式可以计为s[0] * 31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]

关于为什么取31为权，可以参考StackOverflow上的[这个问题](http://stackoverflow.com/questions/299304/why-does-javas-hashcode-in-string-use-31-as-a-multiplier)

主要是因为31是一个奇质数，所以31*i=32*i-i=(i<<5)-i，这种位移与减法结合的计算相比一般的运算快很多。

*返回的hashCode()一样时，其字符串内容不一定一样*，因为上面的方法计算hashCode时可能会发生位数溢出。



## 问题4：Synchronized如何实现可重入？（用个计数器）

​	每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。

原文链接：https://blog.csdn.net/weixin_43698561/article/details/104515904









